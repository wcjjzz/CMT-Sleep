{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ij4Cglx7hnfe"
   },
   "source": [
    "## Get Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gLKQsBn-hgDN",
    "outputId": "dbe85e77-445f-4c6d-8e06-95495a5b7263",
    "ExecuteTime": {
     "end_time": "2025-02-10T09:27:44.518121Z",
     "start_time": "2025-02-10T09:27:41.582566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0+cu113\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "from torch import optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "#import helpers\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils import data\n",
    "# import cv2\n",
    "import math\n",
    "from PIL import Image\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import glob\n",
    "import scipy.signal\n",
    "from einops import rearrange, reduce, repeat\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "print(torch.__version__)\n",
    "\n",
    "\n",
    "from datasets.sleep_edf import split_data, SleepEDF_MultiChan_Dataset\n",
    "from datasets.sleep_edf import SleepEDF_Seq_MultiChan_Dataset_Main as SleepEDF_Seq_MultiChan_Dataset\n",
    "from models.epoch_cmt import Epoch_Cross_Transformer_Network\n",
    "from models.sequence_cmt import Seq_Cross_Transformer_Network \n",
    "from utils.metrics import accuracy, kappa, g_mean, plot_confusion_matrix, confusion_matrix, AverageMeter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T09:27:44.533025Z",
     "start_time": "2025-02-10T09:27:44.519125Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6YSLmONqhyVM",
    "outputId": "eaa51650-2d1e-4039-a2fe-0e2eb0202362",
    "ExecuteTime": {
     "end_time": "2025-02-10T09:27:44.595721Z",
     "start_time": "2025-02-10T09:27:44.534605Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device \n",
    "project_path = \"output\"\n",
    "if not os.path.isdir(project_path):\n",
    "        os.makedirs(project_path)\n",
    "        print(f\"Project directory created at {project_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARyAHPPkl0JS"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T09:27:44.611575Z",
     "start_time": "2025-02-10T09:27:44.596875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\x1.h5'\n",
      " 'C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\x2.h5'\n",
      " 'C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\x3.h5'\n",
      " 'C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\x4.h5']\n",
      "['C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\x5.h5']\n",
      "['C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\mean1.h5'\n",
      " 'C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\mean2.h5'\n",
      " 'C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\mean3.h5'\n",
      " 'C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\mean4.h5']\n",
      "['C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\mean5.h5']\n",
      "['C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\std1.h5'\n",
      " 'C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\std2.h5'\n",
      " 'C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\std3.h5'\n",
      " 'C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\std4.h5']\n",
      "['C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\std5.h5']\n",
      "['C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\eog1.h5'\n",
      " 'C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\eog2.h5'\n",
      " 'C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\eog3.h5'\n",
      " 'C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\eog4.h5']\n",
      "['C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\eog5.h5']\n",
      "['C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\eog_m1.h5'\n",
      " 'C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\eog_m2.h5'\n",
      " 'C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\eog_m3.h5'\n",
      " 'C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\eog_m4.h5']\n",
      "['C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\eog_m5.h5']\n",
      "['C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\eog_std1.h5'\n",
      " 'C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\eog_std2.h5'\n",
      " 'C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\eog_std3.h5'\n",
      " 'C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\eog_std4.h5']\n",
      "['C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\eog_std5.h5']\n",
      "['C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\y1.h5'\n",
      " 'C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\y2.h5'\n",
      " 'C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\y3.h5'\n",
      " 'C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\y4.h5']\n",
      "['C:\\\\Users\\\\Tian_Yumi\\\\Documents\\\\GitHub\\\\CMT-Sleep\\\\data_preparations\\\\extract_dataset_multi_epoch\\\\y5.h5']\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "train_data_list = [0,1,2,3]  \n",
    "val_data_list = [4]  \n",
    "path = r\"C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\"\n",
    "\n",
    "eeg_list = glob.glob(f'{path}/x*.h5')\n",
    "eeg_list.sort()\n",
    "[train_eeg_list, val_eeg_list] = split_data(eeg_list,train_data_list,val_data_list)\n",
    "print(train_eeg_list)\n",
    "print(val_eeg_list)\n",
    "\n",
    "mean_eeg_list = glob.glob(f'{path}/mean*.h5')\n",
    "mean_eeg_list.sort()\n",
    "[train_mean_eeg_list, val_mean_eeg_list] = split_data(mean_eeg_list,train_data_list,val_data_list)\n",
    "print(train_mean_eeg_list)\n",
    "print(val_mean_eeg_list)\n",
    "\n",
    "sd_eeg_list = glob.glob(f'{path}/std*.h5')\n",
    "sd_eeg_list.sort()\n",
    "[train_sd_eeg_list, val_sd_eeg_list] = split_data(sd_eeg_list,train_data_list,val_data_list)\n",
    "print(train_sd_eeg_list)\n",
    "print(val_sd_eeg_list)\n",
    "\n",
    "#########################################################################################################################\n",
    "\n",
    "eog_list = glob.glob(f'{path}/eog*.h5')\n",
    "eog_list.sort()\n",
    "[train_eog_list, val_eog_list] = split_data(eog_list,train_data_list,val_data_list)\n",
    "print(train_eog_list)\n",
    "print(val_eog_list)\n",
    "\n",
    "mean_eog_list = glob.glob(f'{path}/eog_m*.h5')\n",
    "mean_eog_list.sort()\n",
    "[train_mean_eog_list, val_mean_eog_list] = split_data(mean_eog_list,train_data_list,val_data_list)\n",
    "print(train_mean_eog_list)\n",
    "print(val_mean_eog_list)\n",
    "\n",
    "sd_eog_list = glob.glob(f'{path}/eog_std*.h5')\n",
    "sd_eog_list.sort()\n",
    "[train_sd_eog_list, val_sd_eog_list] = split_data(sd_eog_list,train_data_list,val_data_list)\n",
    "print(train_sd_eog_list)\n",
    "print(val_sd_eog_list)\n",
    "\n",
    "\n",
    "# \n",
    "# eeg2_list = glob.glob(f'{path}/eeg*.h5')\n",
    "# eeg2_list.sort()\n",
    "# [train_eeg2_list, val_eeg2_list] = split_data(eeg2_list,train_data_list,val_data_list)\n",
    "# print(train_eeg2_list)\n",
    "# print(val_eeg2_list)\n",
    "# \n",
    "# mean_eeg2_list = glob.glob(f'{path}/eeg_m*.h5')\n",
    "# mean_eeg2_list.sort()\n",
    "# [train_mean_eeg2_list, val_mean_eeg2_list] = split_data(mean_eeg2_list,train_data_list,val_data_list)\n",
    "# print(train_mean_eeg2_list)\n",
    "# print(val_mean_eeg2_list)\n",
    "# \n",
    "# sd_eeg2_list = glob.glob(f'{path}/eeg_s*.h5')\n",
    "# sd_eeg2_list.sort()\n",
    "# [train_sd_eeg2_list, val_sd_eeg2_list] = split_data(sd_eeg2_list,train_data_list,val_data_list)\n",
    "# print(train_sd_eeg2_list)\n",
    "# print(val_sd_eeg2_list)\n",
    "\n",
    "\n",
    "\n",
    "label_list = glob.glob(f'{path}/y*.h5')\n",
    "label_list.sort()\n",
    "[train_label_list, val_label_list] = split_data(label_list,train_data_list,val_data_list)\n",
    "print(train_label_list)\n",
    "print(val_label_list)\n",
    "\n",
    "\n",
    "print(val_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ELCDezM1Qkjs",
    "outputId": "3b314d02-e1cb-4164-8457-93800f41952f",
    "ExecuteTime": {
     "end_time": "2025-02-10T09:28:12.871427Z",
     "start_time": "2025-02-10T09:27:44.612578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\x1.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 2022\n",
      "Shape of each data : (2022, 5, 3000)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\eog1.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 2022\n",
      "Shape of each data : (2022, 5, 3000)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\y1.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 2022\n",
      "Shape of each data : (2022, 5)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\x2.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 2407\n",
      "Shape of each data : (2407, 5, 3000)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\eog2.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 2407\n",
      "Shape of each data : (2407, 5, 3000)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\y2.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 2407\n",
      "Shape of each data : (2407, 5)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\x3.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 2281\n",
      "Shape of each data : (2281, 5, 3000)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\eog3.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 2281\n",
      "Shape of each data : (2281, 5, 3000)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\y3.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 2281\n",
      "Shape of each data : (2281, 5)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\x4.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 1855\n",
      "Shape of each data : (1855, 5, 3000)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\eog4.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 1855\n",
      "Shape of each data : (1855, 5, 3000)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\y4.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 1855\n",
      "Shape of each data : (1855, 5)\n",
      "Labels count: tensor([[0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0]])\n",
      "Labels count weights: tensor([[inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf],\n",
      "        ...,\n",
      "        [inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf]])\n",
      "Shape of EEG : (8565, 5, 3000) , EOG : (8565, 5, 3000)\n",
      "Shape of Labels : torch.Size([8565, 5])\n",
      "Reading Subject wise mean and sd\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\mean1.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 2022\n",
      "Shape of each data : (2022,)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\std1.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 2022\n",
      "Shape of each data : (2022,)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\eog_m1.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 2022\n",
      "Shape of each data : (2022,)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\eog_std1.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 2022\n",
      "Shape of each data : (2022,)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\mean2.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 2407\n",
      "Shape of each data : (2407,)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\std2.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 2407\n",
      "Shape of each data : (2407,)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\eog_m2.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 2407\n",
      "Shape of each data : (2407,)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\eog_std2.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 2407\n",
      "Shape of each data : (2407,)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\mean3.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 2281\n",
      "Shape of each data : (2281,)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\std3.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 2281\n",
      "Shape of each data : (2281,)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\eog_m3.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 2281\n",
      "Shape of each data : (2281,)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\eog_std3.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 2281\n",
      "Shape of each data : (2281,)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\mean4.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 1855\n",
      "Shape of each data : (1855,)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\std4.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 1855\n",
      "Shape of each data : (1855,)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\eog_m4.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 1855\n",
      "Shape of each data : (1855,)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\eog_std4.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 1855\n",
      "Shape of each data : (1855,)\n",
      "Shapes of Mean  : EEG: (8565,), EOG : (8565,)\n",
      "Shapes of Sd  : EEG: (8565,), EOG : (8565,)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\x5.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 1956\n",
      "Shape of each data : (1956, 5, 3000)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\eog5.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 1956\n",
      "Shape of each data : (1956, 5, 3000)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\y5.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 1956\n",
      "Shape of each data : (1956, 5)\n",
      "Labels count: tensor([[0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0]])\n",
      "Labels count weights: tensor([[inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf],\n",
      "        ...,\n",
      "        [inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf],\n",
      "        [inf, inf, inf, inf, inf]])\n",
      "Shape of EEG : (1956, 5, 3000) , EOG : (1956, 5, 3000)\n",
      "Shape of Labels : torch.Size([1956, 5])\n",
      "Reading Subject wise mean and sd\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\mean5.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 1956\n",
      "Shape of each data : (1956,)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\std5.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 1956\n",
      "Shape of each data : (1956,)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\eog_m5.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 1956\n",
      "Shape of each data : (1956,)\n",
      "Reading from C:\\Users\\Tian_Yumi\\Documents\\GitHub\\CMT-Sleep\\data_preparations\\extract_dataset_multi_epoch\\eog_std5.h5 ====================================================\n",
      "Keys in the h5py file : <KeysViewHDF5 ['data']>\n",
      "Number of samples : 1956\n",
      "Shape of each data : (1956,)\n",
      "Shapes of Mean  : EEG: (1956,), EOG : (1956,)\n",
      "Shapes of Sd  : EEG: (1956,), EOG : (1956,)\n"
     ]
    }
   ],
   "source": [
    "num_seq = 5\n",
    "train_dataset = SleepEDF_Seq_MultiChan_Dataset(eeg_file = train_eeg_list , \n",
    "                                           eog_file = train_eog_list, \n",
    "                                           label_file = train_label_list, \n",
    "                                           device = device, mean_eeg_l = train_mean_eeg_list, sd_eeg_l = train_sd_eeg_list, \n",
    "                                           mean_eog_l = train_mean_eog_list, sd_eog_l = train_sd_eog_list, \n",
    "                                           sub_wise_norm = True,\n",
    "                                           num_seq = num_seq,\n",
    "                                           transform=transforms.Compose([\n",
    "                                               transforms.ToTensor(),\n",
    "                                                ]) )\n",
    "\n",
    "val_dataset = SleepEDF_Seq_MultiChan_Dataset(eeg_file = val_eeg_list ,\n",
    "                                         eog_file = val_eog_list, \n",
    "                                         label_file = val_label_list, \n",
    "                                         device = device, mean_eeg_l = val_mean_eeg_list, sd_eeg_l = val_sd_eeg_list,\n",
    "                                         mean_eog_l = val_mean_eog_list, sd_eog_l = val_sd_eog_list,\n",
    "                                         sub_wise_norm = True, num_seq = num_seq,\n",
    "                                         transform=transforms.Compose([\n",
    "                                               transforms.ToTensor(),\n",
    "                                                ]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "IpXQ66ipml-q",
    "ExecuteTime": {
     "end_time": "2025-02-10T09:28:12.886769Z",
     "start_time": "2025-02-10T09:28:12.873699Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "train_data_loader = data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "val_data_loader = data.DataLoader(val_dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "O3c5Neaqmu6-",
    "outputId": "2dd0adc7-2e82-48aa-81b8-ac34d19b7f74",
    "ExecuteTime": {
     "end_time": "2025-02-10T09:28:13.291162Z",
     "start_time": "2025-02-10T09:28:12.887772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG batch shape: torch.Size([8, 3000, 5, 5])\n",
      "EOG batch shape: torch.Size([8, 3000, 5, 5])\n",
      "Labels batch shape: torch.Size([8, 5, 5])\n",
      "EEG batch shape: torch.Size([8, 3000, 5, 5])\n",
      "EOG batch shape: torch.Size([8, 3000, 5, 5])\n",
      "Labels batch shape: torch.Size([8, 5, 5])\n",
      "EEG Minimum :-6.710402466983561\n",
      "EEG Maximum :7.445122580911266\n",
      "EOG Minimum :-10.94195434791585\n",
      "EOG Maximum :10.3628641533131\n",
      "EEG Mean :6.997932492580954e-05\n",
      "EEG Standard Deviation :1.1425711498208253\n",
      "EOG Mean :-0.00013029404963406247\n",
      "EOG Standard Deviation :0.9744379567369932\n"
     ]
    }
   ],
   "source": [
    "eeg_data, eog_data, label = next(iter(train_data_loader))\n",
    "print(f\"EEG batch shape: {eeg_data.size()}\")\n",
    "print(f\"EOG batch shape: {eog_data.size()}\")\n",
    "# print(f\"EMG batch shape: {eeg2_data.size()}\")\n",
    "print(f\"Labels batch shape: {label.size()}\")\n",
    "\n",
    "# eeg_data_temp = torch.reshape(eeg_data[0],(1,eeg_data[0].shape[1]*eeg_data[0].shape[2]))\n",
    "# eog_data_temp = torch.reshape(eog_data[0],(1,eog_data[0].shape[1]*eog_data[0].shape[2]))\n",
    "# \n",
    "# t = np.arange(0,30,1/100)\n",
    "# plt.figure(figsize = (10,10))\n",
    "# plt.plot(eeg_data_temp[0].squeeze())\n",
    "# plt.plot(eog_data_temp[0].squeeze()+5)\n",
    "# # plt.plot(t,eeg2_data[0].squeeze()+10)\n",
    "# plt.title(f\"Label {label[0].squeeze()}\")\n",
    "# plt.show()\n",
    "\n",
    "eeg_data, eog_data, label = next(iter(val_data_loader))\n",
    "print(f\"EEG batch shape: {eeg_data.size()}\")\n",
    "print(f\"EOG batch shape: {eog_data.size()}\")\n",
    "# print(f\"EMG batch shape: {eeg2_data.size()}\")\n",
    "print(f\"Labels batch shape: {label.size()}\")\n",
    "# \n",
    "# eeg_data_temp = torch.reshape(eeg_data[0],(1,eeg_data[0].shape[1]*eeg_data[0].shape[2]))\n",
    "# eog_data_temp = torch.reshape(eog_data[0],(1,eog_data[0].shape[1]*eog_data[0].shape[2]))\n",
    "# \n",
    "# # t = np.arange(0,30,1/100)\n",
    "# plt.figure(figsize = (10,10))\n",
    "# plt.plot(eeg_data_temp[0].squeeze())\n",
    "# plt.plot(eog_data_temp[0].squeeze()+5)\n",
    "# # plt.plot(t,eeg2_data[0].squeeze()+10)\n",
    "# plt.title(f\"Label {label[0].squeeze()}\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "print(f\"EEG Minimum :{eeg_data.min()}\")\n",
    "print(f\"EEG Maximum :{eeg_data.max()}\")\n",
    "print(f\"EOG Minimum :{eog_data.min()}\")\n",
    "print(f\"EOG Maximum :{eog_data.max()}\")\n",
    "# print(f\"EMG Minimum :{eeg2_data.min()}\")\n",
    "# print(f\"EMG Maximum :{eeg2_data.max()}\")\n",
    "\n",
    "\n",
    "print(f\"EEG Mean :{torch.mean(eeg_data)}\")\n",
    "print(f\"EEG Standard Deviation :{torch.std(eeg_data)}\")\n",
    "print(f\"EOG Mean :{torch.mean(eog_data)}\")\n",
    "print(f\"EOG Standard Deviation :{torch.std(eog_data)}\")\n",
    "# print(f\"EMG Mean :{torch.mean(eeg2_data)}\")\n",
    "# print(f\"EMG Standard Deviation :{torch.std(eeg2_data)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAv7VEk-z9Ch"
   },
   "source": [
    "### Classification Model Sequence Cross-Modal Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BBI0JVRcz9Ck",
    "outputId": "5a21dd30-94a8-4779-b291-d4cb1a97eae2",
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2025-02-10T09:28:13.292410Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "d_model = 256 \n",
    "dim_feedforward=1024  #\n",
    "window_size = 50#25 50\n",
    "Net = Seq_Cross_Transformer_Network(d_model = d_model, dim_feedforward=dim_feedforward,\n",
    "                                window_size = window_size ).to(device)\n",
    "# Net = torch.load('/home/jathu/fyp_g15_sleep_monitoring/Experiments/Sleep_edfx/V2_Seq_CMT/V2SEQ-32/checkpoint_model_best_kappa.pth.tar').to(device)\n",
    "\n",
    "lr = 0.001#0.001\n",
    "beta_1 =  0.9    \n",
    "beta_2 =  0.999    \n",
    "eps = 1e-9\n",
    "n_epochs = 1000\n",
    "weights = torch.tensor([1., 2., 1., 2., 2.]) \n",
    "print(f\"weights: {weights}\")\n",
    "criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "optimizer = torch.optim.Adam(Net.parameters(), lr=lr, betas=(beta_1, beta_2),eps = eps, weight_decay = 0.0001)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5) \n",
    "\n",
    "pred= Net(eeg_data.float().to(device), eog_data.float().to(device))\n",
    "print(len(pred),pred[0].shape)#,cls_outs.shape,len(feat_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_4Pl9HUrz9Cn",
    "outputId": "378a408d-cc32-4248-a2b6-a036a00d34e2",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Training the model\n",
    "best_val_acc = 0\n",
    "best_val_kappa = 0\n",
    "for epoch_idx in range(n_epochs):  # loop over the dataset multiple times\n",
    "    \n",
    "    Net.train()\n",
    "    print(f'===========================================================Training Epoch : [{epoch_idx+1}/{n_epochs}] ===========================================================================================================>')\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    \n",
    "    losses = AverageMeter()\n",
    "    val_losses = AverageMeter()\n",
    "    \n",
    "    train_accuracy = AverageMeter()\n",
    "    val_accuracy = AverageMeter()\n",
    "\n",
    "    train_sensitivity = AverageMeter()\n",
    "    val_sensitivity = AverageMeter()\n",
    "    \n",
    "    train_specificity = AverageMeter()\n",
    "    val_specificity = AverageMeter()\n",
    "\n",
    "    train_gmean = AverageMeter()\n",
    "    val_gmean = AverageMeter()\n",
    "\n",
    "    train_kappa = AverageMeter()\n",
    "    val_kappa = AverageMeter()\n",
    "\n",
    "    train_f1_score = AverageMeter()\n",
    "    val_f1_score = AverageMeter()\n",
    "\n",
    "    train_precision = AverageMeter()\n",
    "    val_precision = AverageMeter()\n",
    "\n",
    "    class1_sens = AverageMeter()\n",
    "    class2_sens = AverageMeter()\n",
    "    class3_sens = AverageMeter()\n",
    "    class4_sens = AverageMeter()\n",
    "    class5_sens = AverageMeter()\n",
    "\n",
    "    class1_spec = AverageMeter()\n",
    "    class2_spec = AverageMeter()\n",
    "    class3_spec = AverageMeter()\n",
    "    class4_spec = AverageMeter()\n",
    "    class5_spec = AverageMeter()\n",
    "\n",
    "    class1_f1 = AverageMeter()\n",
    "    class2_f1 = AverageMeter()\n",
    "    class3_f1 = AverageMeter()\n",
    "    class4_f1 = AverageMeter()\n",
    "    class5_f1 = AverageMeter()\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    for batch_idx, data_input in enumerate(train_data_loader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        data_time.update(time.time() - end)\n",
    "        eeg,eog, labels = data_input\n",
    "        cur_batch_size = len(eeg)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = Net(eeg.float().to(device), eog.float().to(device))\n",
    "\n",
    "        loss = 0\n",
    "        for ep in range(num_seq):\n",
    "          loss += criterion(outputs[ep].cpu(), labels[:,ep])\n",
    "\n",
    "\n",
    "          train_accuracy.update(accuracy(outputs[ep].cpu(), labels[:,ep]))\n",
    "          _,_,_,_,sens,spec,f1, prec = confusion_matrix(outputs[ep].cpu(), labels[:,ep], 5, cur_batch_size)\n",
    "          train_sensitivity.update(sens)\n",
    "          train_specificity.update(spec)\n",
    "          train_f1_score.update(f1)\n",
    "          train_precision.update(prec)\n",
    "          train_gmean.update(g_mean(sens, spec))\n",
    "          train_kappa.update(kappa(outputs[ep].cpu(), labels[:,ep]))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "        losses.update(loss)\n",
    "        \n",
    "       \n",
    "        \n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if batch_idx % 1000 == 0:\n",
    "            msg = 'Epoch: [{0}/{3}][{1}/{2}]\\t' \\\n",
    "                  'Train_Loss {loss.val:.5f} ({loss.avg:.5f})\\t'\\\n",
    "                  'Train_Acc {train_acc.val:.5f} ({train_acc.avg:.5f})\\t'\\\n",
    "                  'Train_Kappa {train_kap.val:.5f}({train_kap.avg:.5f})\\t'\\\n",
    "                  'Train_MF1 {train_mf1.val:.5f}({train_mf1.avg:.5f})\\t'\\\n",
    "                  'Train_G-Mean {train_gmean.val:.5f}({train_gmean.avg:.5f})\\t'\\\n",
    "                  'Train_Precision {train_prec.val:.5f}({train_prec.avg:.5f})\\t'\\\n",
    "                  'Train_Sensitivity {train_sens.val:.5f}({train_sens.avg:.5f})\\t'\\\n",
    "                  'Train_Specificity {train_spec.val:.5f}({train_spec.avg:.5f})\\t'\\\n",
    "                  'Time {batch_time.val:.3f}s ({batch_time.avg:.3f}s)\\t' \\\n",
    "                  'Speed {speed:.1f} samples/s\\t' \\\n",
    "                  'Data {data_time.val:.3f}s ({data_time.avg:.3f}s)\\t'.format(\n",
    "                      epoch_idx+1, batch_idx, len(train_data_loader),n_epochs, batch_time=batch_time,\n",
    "                      speed=data_input[0].size(0)/batch_time.val,\n",
    "                      data_time=data_time, loss=losses, train_acc = train_accuracy,\n",
    "                      train_sens =train_sensitivity, train_spec = train_specificity, train_gmean = train_gmean,\n",
    "                      train_kap = train_kappa, train_mf1 = train_f1_score, train_prec = train_precision)\n",
    "            \n",
    "            print(msg)\n",
    "\n",
    "\n",
    "    #evaluation\n",
    "    with torch.no_grad():\n",
    "      Net.eval()\n",
    "      for batch_val_idx, data_val in enumerate(val_data_loader):\n",
    "        val_eeg,val_eog, val_labels = data_val\n",
    "        cur_val_batch_size = len(val_eeg)\n",
    "        pred = Net(val_eeg.float().to(device), val_eog.float().to(device))\n",
    "        \n",
    "        val_loss = 0\n",
    "        for ep in range(num_seq):\n",
    "          val_loss += criterion(pred[ep].cpu(), val_labels[:,ep])\n",
    "\n",
    "          val_accuracy.update(accuracy(pred[ep].cpu(), val_labels[:,ep]))\n",
    "          sens_list,spec_list,f1_list,prec_list, sens,spec,f1,prec = confusion_matrix(pred[ep].cpu(), val_labels[:,ep],  5, cur_val_batch_size)\n",
    "          val_sensitivity.update(sens)\n",
    "          val_specificity.update(spec)\n",
    "          val_f1_score.update(f1)\n",
    "          val_precision.update(prec)\n",
    "          val_gmean.update(g_mean(sens, spec))\n",
    "          val_kappa.update(kappa(pred[ep].cpu(), val_labels[:,ep]))\n",
    "\n",
    "          class1_sens.update(sens_list[0])\n",
    "          class2_sens.update(sens_list[1])\n",
    "          class3_sens.update(sens_list[2])\n",
    "          class4_sens.update(sens_list[3])\n",
    "          class5_sens.update(sens_list[4])\n",
    "\n",
    "          class1_spec.update(spec_list[0])\n",
    "          class2_spec.update(spec_list[1])\n",
    "          class3_spec.update(spec_list[2])\n",
    "          class4_spec.update(spec_list[3])\n",
    "          class5_spec.update(spec_list[4])\n",
    "\n",
    "          class1_f1.update(f1_list[0])\n",
    "          class2_f1.update(f1_list[1])\n",
    "          class3_f1.update(f1_list[2])\n",
    "          class4_f1.update(f1_list[3])\n",
    "          class5_f1.update(f1_list[4])\n",
    "\n",
    "        \n",
    "        val_losses.update(val_loss)#.data.item())\n",
    "        \n",
    "\n",
    "      print(batch_val_idx)\n",
    "\n",
    "     \n",
    "\n",
    "      print(f'===========================================================Epoch : [{epoch_idx+1}/{n_epochs}]  Evaluation ===========================================================================================================>')\n",
    "      print(\"Training Results : \")\n",
    "      print(f\"Training Loss     : {losses.avg}, Training Accuracy      : {train_accuracy.avg}, Training G-Mean      : {train_gmean.avg}\") \n",
    "      print(f\"Training Kappa      : {train_kappa.avg},Training MF1     : {train_f1_score.avg}, Training Precision      : {train_precision.avg}, Training Sensitivity      : {train_sensitivity.avg}, Training Specificity      : {train_specificity.avg}\")\n",
    "      \n",
    "      print(\"Validation Results : \")\n",
    "      print(f\"Validation Loss   : {val_losses.avg}, Validation Accuracy : {val_accuracy.avg}, Validation G-Mean      : {val_gmean.avg}\") \n",
    "      print(f\"Validation Kappa     : {val_kappa.avg}, Validation MF1      : {val_f1_score.avg}, Validation Precision      : {val_precision.avg},  Validation Sensitivity      : {val_sensitivity.avg}, Validation Specificity      : {val_specificity.avg}\")\n",
    "    \n",
    "\n",
    "      print(f\"Class wise sensitivity W: {class1_sens.avg}, S1: {class2_sens.avg}, S2: {class3_sens.avg}, S3: {class4_sens.avg}, R: {class5_sens.avg}\")\n",
    "      print(f\"Class wise specificity W: {class1_spec.avg}, S1: {class2_spec.avg}, S2: {class3_spec.avg}, S3: {class4_spec.avg}, R: {class5_spec.avg}\")\n",
    "      print(f\"Class wise F1  W: {class1_f1.avg}, S1: {class2_f1.avg}, S2: {class3_f1.avg}, S3: {class4_f1.avg}, R: {class5_f1.avg}\")\n",
    "\n",
    "     \n",
    "\n",
    "      if val_accuracy.avg > best_val_acc or (epoch_idx+1)%100==0 or val_kappa.avg > best_val_kappa:\n",
    "          if val_accuracy.avg > best_val_acc:\n",
    "           \n",
    "            best_val_acc = val_accuracy.avg\n",
    "            print(\"================================================================================================\")\n",
    "            print(\"                                          Saving Best Model (ACC)                                     \")\n",
    "            print(\"================================================================================================\")\n",
    "            torch.save(Net, f'{project_path}/checkpoint_model_best_acc.pth.tar')\n",
    "          if val_kappa.avg > best_val_kappa:\n",
    "           \n",
    "            best_val_kappa = val_kappa.avg\n",
    "            print(\"================================================================================================\")\n",
    "            print(\"                                          Saving Best Model (Kappa)                                    \")\n",
    "            print(\"================================================================================================\")\n",
    "            torch.save(Net, f'{project_path}/checkpoint_model_best_kappa.pth.tar')\n",
    "          if (epoch_idx+1)%50==0:\n",
    "            torch.save(Net, f'{project_path}/checkpoint_model_epoch_{epoch_idx+1}.pth.tar')\n",
    "    lr_scheduler.step()\n",
    "print('========================================Finished Training ===========================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "mp-EzMvdOlRO",
    "BGlbwPN1z9Co"
   ],
   "name": " Jathu_Sleep_Stage_Classification_(Cross Transformer)_sleepEDF_(EEG,EEG2,EOG).ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "94c91063cbfafe7dd443522ce7f45eaee09f9c12e6866a8b2d3ce13a69535fc6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
